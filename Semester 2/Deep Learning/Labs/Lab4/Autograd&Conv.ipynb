{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n",
    "\n",
    "# Define network module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden=200):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Transform inputs and targets into autograd variables\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train function\n",
    "def train_model(model, train_input, train_target, mini_batch_size, print_progress=False):\n",
    "    # Set hypterparameters\n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "    max_iter = 25\n",
    "    print_step = 5\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        sum_loss = 0\n",
    "        # Iterate data in mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss += loss.item()\n",
    "            # Reset gradients for the parameters\n",
    "            model.zero_grad()\n",
    "            # Propagate gradients through the network\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        # Print progress\n",
    "        if print_progress and (step % print_step == 0 or step == max_iter - 1):\n",
    "            print(f'Step {step}/{max_iter-1}:\\tLoss {sum_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test function\n",
    "def compute_nb_errors(model, input, target):\n",
    "    output = model(input)\n",
    "    _, preds = output.max(1)\n",
    "    _, target = target.max(1)\n",
    "    return (preds != target).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error 15.06\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size = 100\n",
    "num_runs = 10\n",
    "\n",
    "errs = []\n",
    "for _ in range(num_runs):\n",
    "    model = Net()\n",
    "    # Train model\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    # Test model\n",
    "    errs.append(compute_nb_errors(model, test_input, test_target))\n",
    "# Compute the average number of errors\n",
    "avg_err = 100 * np.mean(errs) / test_input.size(0)\n",
    "print(f'Test error {avg_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden 10\tTest error 17\n",
      "Hidden 50\tTest error 18\n",
      "Hidden 200\tTest error 15\n",
      "Hidden 500\tTest error 13\n",
      "Hidden 1000\tTest error 11\n"
     ]
    }
   ],
   "source": [
    "# Test several hidden layer sizes\n",
    "hiddens = [10, 50, 200, 500, 1000]\n",
    "\n",
    "for hidden in hiddens:\n",
    "    model = Net(hidden)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    err = 100 * compute_nb_errors(model, test_input, test_target) / test_input.size(0)\n",
    "    print(f'Hidden {hidden}\\tTest error {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new network\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, hidden=200):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error 22.98\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size = 100\n",
    "num_runs = 10\n",
    "\n",
    "errs = []\n",
    "for _ in range(num_runs):\n",
    "    model = Net2()\n",
    "    # Train model\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    # Test model\n",
    "    errs.append(compute_nb_errors(model, test_input, test_target))\n",
    "# Compute the average number of errors\n",
    "avg_err = 100 * np.mean(errs) / test_input.size(0)\n",
    "print(f'Test error {avg_err}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
